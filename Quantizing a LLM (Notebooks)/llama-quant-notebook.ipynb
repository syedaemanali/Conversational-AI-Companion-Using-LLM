{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token = \"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\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-06T10:59:59.853120Z","iopub.execute_input":"2024-08-06T10:59:59.854052Z","iopub.status.idle":"2024-08-06T11:00:00.461128Z","shell.execute_reply.started":"2024-08-06T10:59:59.853984Z","shell.execute_reply":"2024-08-06T11:00:00.459861Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade transformers bitsandbytes peft","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\nfrom peft import LoraConfig, PeftModel","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _8bit():\n    model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\",\n                                                torch_dtype=torch.float16,\n                                                 quantization_config=BitsAndBytesConfig(\n                                                load_in_8bit=True\n                                                ))\n    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T11:05:20.468727Z","iopub.execute_input":"2024-08-06T11:05:20.469158Z","iopub.status.idle":"2024-08-06T11:05:20.474726Z","shell.execute_reply.started":"2024-08-06T11:05:20.469126Z","shell.execute_reply":"2024-08-06T11:05:20.473731Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def _16bit():\n    model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\",\n                                                torch_dtype=torch.float16\n                                                ).to('cuda')\n    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer = input(print(\"Enter E for 8bit and S for 16bit quantization\"))\nif answer == 'E':\n    _8bit()\nelif answer == 'S':\n    _16bit()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T11:05:22.474415Z","iopub.execute_input":"2024-08-06T11:05:22.475206Z","iopub.status.idle":"2024-08-06T11:05:24.773535Z","shell.execute_reply.started":"2024-08-06T11:05:22.475174Z","shell.execute_reply":"2024-08-06T11:05:24.772051Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Enter E for 8bit and S for 16bit quantization\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"None E\n"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter E for 8bit and S for 16bit quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43m_8bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m     _16bit()\n","Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36m_8bit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_8bit\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                                 torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m      4\u001b[0m                                                  quantization_config\u001b[38;5;241m=\u001b[39mBitsAndBytesConfig(\n\u001b[1;32m      5\u001b[0m                                                 load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                                                 ))\n\u001b[1;32m      7\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'AutoModelForCausalLM' is not defined"],"ename":"NameError","evalue":"name 'AutoModelForCausalLM' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}